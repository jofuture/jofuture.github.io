학습목표 : AI분야에서 선형대수가 어떻게 적용이 되고 있는지 살펴보자1 - 선형대수 기초학습

학습정리 기준 :

1\. 데이터 사이언티스트에게 **'선형대수' 지식이 왜 필요한가**

2\. **스칼라 vs 벡터**, 벡터의 개념학습 → **둘은 어떤 차이가 있는지**, 벡터의 속성학습

3\. **벡터와 행렬는 서로 어떤 관계**를 가지고 있는가

4\. **공분산, 상관계수의 목적**, 왜 상관관계를 찾는지, **머신러닝/딥러닝 관점**에서 학습해볼 것

5\. 벡터의 **orthogonality, span, basis, rank, Gaussian Elimination**를 키워드중심으로 정리하면서

이 keyword가 어떤 연관성을 가지는지 확인할 것!

<img src="https://blog.kakaocdn.net/dn/FfC9j/btrhZnw2Ttw/R9y6I3kbmVXLR1U6LQ9Z5k/img.png">

원래 선형대수학은 연립방정식을 손쉽게 풀고자 하는 고민으로부터 시작되었습니다.

머신러닝은 본질적으로는 컴퓨터가 이해할 수 있는 대량의 데이터,

즉 숫자를 이용해 복잡한 계산을 수행하는 것 이므로 선형대수학의 수식과 계산 기법을 사용하면

최소한의 타이핑 만으로도 대량의 계산을 손쉽게 컴퓨터에게 지시하는것이 가능해 집니다.

#### **선형대수란?**

복잡한 비선형 문제를 간단한 선형 방정식으로 변환하여 문제를 해결할 수 있어, 

자연과학과 물리학, 컴퓨터 그래픽 등의 다양한 분야에서 활용된다. 머신러닝에서는 PCA 등을 이용하여 차원(dimension)을 줄이거나, 학습(training)할 때 계산 과정을 줄이는 데 활용된다

또한 아래 개념등을 이용함으로써 복수의 값이나 변수를 한꺼번에 처리할 수 있도록

수식을 간결하게 표현할 수 있다.

---

#### **벡터와 행렬의 관계**

벡터 (Vector)

-   크기와 방향을 갖는 어떠한 물리량
-   패턴 인식에서 인식 대상이 되는 객체가 특징으로 표현되고,  
    특징은 차원을 가진 벡터(열 벡터)로 표현 : 특징벡터

ex) 이번달 쓴 용돈의 항목별 지출 상황 

크기 및 방향도 생각해 볼 수있는데 위의 예시처럼 용돈 백터를 보면 용돈은 얼마만큼, 어떤 방향으로 쓰는지가 나온다.

100명의 학생에 대해 과자와 책 지출액을 조사하여 각각을 X,Y축으로 갖는 평면에 나타내보면

요즘 학생들의 용돈 사용의 경향이 나타날 것이다.

행렬 : 같은 크기의 벡터를 복수로 늘어놓은 것,

붙여서 된 결과물이 사각형이기에 이를 가로 (행-row), 세로(열-column)벡터의 배열로 볼 수 있다.

행렬에 대한 모든 연산이 벡터 연산의 조합으로 환원될 수 있다.

반대로 벡터는 행/열 방향의 원소가 하나인 행렬의 특수한 형태로 볼 수 있기에, 실제 컴퓨터 프로그램으로는 벡터를 따로 구현하지 않는 경우도 많다.

#### **스칼라 vs 벡터**

벡터는 스칼라를 한 뱡향으로 정렬한 것이다. ( 스칼라들의 집합을 묶어놓은 것 )

스칼라는 행렬을 구성하는 요소인 각 숫자를 의미하며, 이는 행렬의 구성 요소중 최소 단위에 해당한다.

<img src="https://blog.kakaocdn.net/dn/cxsfGw/btrh0C2NNl8/Nhn5dmVlNRc8IGs91t5Rgk/img.png">

**Basis**

선형대수학에서 벡터 공간(vector space)이란 벡터 집합이 존재할 때, 해당 벡터들로 구성할 수 있는 공간

어떤 벡터 공간의 기저(basis)는 그 벡터공간을 선형생성하는 선형독립인 벡터들이다.

즉 기저의 조합으로 공간을 생성할 수 있다. 

ex) 집 주소를 구성하는 기저는 '도','시','동'이라고 할 수 있다.

-   기저 벡터들은 공간(space)을 생성(span) 한다.
-   기저 벡터들은 선형독립(independent)이다.

**Span**

또한 벡터 공간의 일부분을 부분 공간(subspace)라고 하는데 집합에서 전체 집합과 부분 집합의 관계라고 생각하면 된다. 예를 들어, 전체 공간을 3차원 공간이라고 했을 때 전체 공간의 일부인 선(line)이나 면(plain)은 3차원 공간의 부분

공간이라고 할 수 있다. 이런 관계를 설명하는 데 스팬(Span) 이라는 개념이 사용된다.

즉, 벡터들 v1, v2, v3, ..., vn 의 모든 선형결합으로 이루어진 집합을

이 벡터들의 생성(span)이라 하고, Span{v1, v2, v3, ... , vn} 라고 쓴다.


**차원(dimension)**

기저와 함께 나오는 개념인 차원은 기저 벡터의 개수를 의미한다.

즉,벡터 공간을 구성하는 데 필요한 최소한의 벡터 개수가 차원이다.

**Rank**

어떤 행렬 A의 랭크는 해당 행렬의 열벡터에 의해 span된 벡터공간의 차원 이라고 한다.

<img src="https://blog.kakaocdn.net/dn/bFW5Nr/btrh2hRDmKN/aYd6hr8ItsGo4rsT0ng0Lk/img.jpg">

rank는 얻을 수 있는 정보양과 관련이 있다**.** rank가 작으면 데이터셋에서 얻을 수 있는 정보는 줄어들게 되는데,

별 것 아닐 수 있지만 이러한 데이터셋과 피쳐는 ML 모델에 상당한 방해를 하며, 영향을 끼친다.

**Orthogonality**

-   직교성이라고 한다.
-   수학적으로, 각 요소들이 서로 독립적임을 나타내는 용어
-   일반적으로, 신호/현상 상호 간에 전혀 관련성이 없음을 의미

---

#### **공분산, 상관계수의 목적, 머신러닝/딥러닝에서의 관점은?**

**공분산이란?** 두 개의 확률변수의 상관정도를 나타내는 값이다.

즉 X,Y에 대해서 공통적으로 나타내는 분산이며 X,Y가 어떤 방향성을 갖고 있는지 표시한다.  
  
머신러닝/딥러닝에서의 관점은 공분산은 서로 다른 데이터의 분포가 어느정도 유사성을 보이는 지표이다.

-   두 변수가 얼마나 다른가를 공분산을 사용해서 일반화
-   두 변수 값이 서로 독립이라면 공분산의 값은 0
-   두 값이 함께 증가하거나 감소하면 공분산은 양수
-   한 값이 증가하는데 다른 값이 감소함을 보이면 공분산은 음수

<img src="https://blog.kakaocdn.net/dn/bYcfKh/btrhTcc5s89/CQZy8BfUnCgMHN6w3Gkmsk/img.png">

**공분산 공식**  = \[((개별 X측정치) - (X의 평균)) x ((개별 Y측정치)-(Y의 평균)\]\]의 총합/(조합을 이루는개수)

                  -> \[(X의 평균편차) x (Y의 평균편차)\]의 총합/(조합을 이루는 개수)

**공분산의 한계**

-   단위,범위에 영향을 받는다  
    즉 확률변수가 큰 값을 다룬다면 공분산도 커지고, 작은 값을 다룬다면 공분산은 작아진다.  
    예를 들어 키를 다룬다고 했을때 cm를 쓴다면 주로 100~200사이의 값이 수집될 것이고,  
    mm를 쓴다면 1,000~2,000 사이의 값이 수집 될 것이다. 표준화 시켜줄 필요가 있는 것이다.  
    이러한 한계를 극복하기 위해 나온것이 상관관계이다.

**상관계수란?**

-   두 변수간에 어떤 선형 또는 비선형적 관계를 갖고 있는 지를 분석하는 방법이다.  
    이때 두 변수간의 관계의 강도를 상관계수(Correlation coefficient) 라고 한다.
-   보편적으로 사용되는 것이 피어슨 상관계수이다.  
    보통 피어슨 상관계수값이 0에 가까울 수록 상관관계는 없다고 해석 되며,  
    +1, -1에 가까울수록 상관관계가 강하다고 해석한다.  
    공분산과는 달리 피어슨 상관계수는 -1부터 1사이에만 존재하므로, 단위에 영향을 받지 않습니다.

**상관계수의 한계**

-   수학적 관계이지 속성의 관계를 표현하지 않는다.  
    ex) 언어성적과 수학성적 , 아이스크림과 범죄율
-   선형관계의 측도이다.  
    곡선관계는 찾아내지 못한다.
-   자료분석의 초기단계로만 이용

그럼에도 불구하고 자주 사용되는 이유는 간단하고 직관적이라는 장점때문이다.

---

**Gaussian Elimination**

가우스 소거법이라 불리고 Row Reduction으로 알려진다.

확장행렬을 기학행 사다리꼴로 바꿔나가는 알고리즘

즉 선형시스템을 풀기위한 선형대수의 알고리즘이다.

Gaussian Elimination 은 주어진 매트릭스를 "Row-Echelon form"으로 바꾸는 계산과정입니다.

여기서 "Row-Echelon form"이란, 각 행에 대해서 왼쪽에 1, 그 이후 부분은 0으로 이뤄진 형태입니다.

**출처:** [https://losskatsu.github.io/linear-algebra/basis/#1%EC%A7%91-%EC%A3%BC%EC%86%8C%EC%97%90-%EB%8C%80%ED%95%9C-%EB%B9%84%EC%9C%A0](https://losskatsu.github.io/linear-algebra/basis/#1%EC%A7%91-%EC%A3%BC%EC%86%8C%EC%97%90-%EB%8C%80%ED%95%9C-%EB%B9%84%EC%9C%A0)
https://www.calculushowto.com/scalar-function/
[https://wegonnamakeit.tistory.com/40](https://wegonnamakeit.tistory.com/40)

책<선형대수와 통계학으로 배우는 머신러닝>
