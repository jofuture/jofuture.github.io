학습목표 : 머신러닝 모델이 얼마나 잘 작동하는지 통계적으로 확인하는 척도에 대해서 알아보자.

학습정리기준 : 

1\. 정확도, 오차행렬, 정밀도, 재현율, f1 score의 개념에 대해서 알아보자.

2\. ROC, AUC 그래프를 봤을 때 어떤 결과가 더 좋은지판단해보자.

3\. 실제 코드실습.

## **지도학습의 성능평가지표들**

| 지도학습 | Baseline (기준모델) | Evaluation Metric (성능평가지표) |
| --- | --- | --- |
| Regression   (회귀) | 실제값과 예측값의 오차 평균값 | MAE , MSE, R^2 |
| Classification   (분류) | Majority(최빈값) | **Accuracy (정확도)**   **Confusion Matrix (오차행렬)**   **Precision (정밀도)**   **Recall (재현율)**   **F1 Score (F1스코어)**   **ROC AUC** |

## **분류 모델의 성능 평가 지표 Accuracy, Recall, Precision, F1**

분류의 평가 방법에는 이 데이터가 얼마나 정확하고 오류가 적게 발생하는가에 기반하지만,

단순히 이러한 정확도(accuracy)만으로 판단했다가는 잘못된 평가 결과에 빠질 수 있다.

특히 0과 1, 긍정 과 부정을 판단하는 이진분류에서는 다른평가 지표가 더 중요시 되는경우가 많다.

그리고 정확도(accuracy)는 불균형(imbalanced)한 레이블 값 분포에서 모델의 성능을 판단할 때 적합하지 않다.

그래서 우리는 여러가지 방법을 다양하게 활용해야한다.

이진 분류에서 성능 지표로서 잘 활용되는 오차행렬은 분류 모델이 얼마나 헷갈리고(confused)있는지도 함께 보여주는 지표이다.

즉, 이진 분류에서 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측오류가 발생하고 있는지를 함께 나타내는 지표이다.

<img src="https://blog.kakaocdn.net/dn/bdbbcO/btrjqpHTNYr/Uhik9VcVxUBdwcrGy3sOdK/img.jpg">

위의 그림은 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떠한 유형을 가지고 매핑이 되는지를 나타내는 표 이다. 실제값이 positive인지 negative인지와 예측값이 positive인지 negative인지를 나태내고 있다.

-   T는 True를 의미하며, F는 False를 의미한다. / True는 예측값과 실제값이 같은것이며, False는 예측값과 실제값이 다름을 의미한다
-   P는 Positive를 의미하며, N은 Negative를 의미한다. /즉, 예측값이 부정(0),긍정(1)을 의미한다.

### **정확도**

정확도(accuracy)는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표이다.

높을수록 좋은 모형이다. 일반적으로 학습에서 최적화 목적함수로 사용된다.

-   **정확도(Accuracy) = (예측 결과가 동일한 데이터 건수) / (전체 예측 데이터 건수)**

정확도는 직관적으로 모델 예측 성능을 나타내는 평가 지표이다.

하지만 이진 분류의 경우 데이터의 구성에 따라 모델 성능을 왜곡할 수 있기 때문에

정확도 수치 하나만 가지고 성능을 평가하지 않는다.

따라서 우리는 이렇게 이진분류인 데이터 특히, 불균형(imbalanced)한 레이블 값 분포의 경우

accuracy로 성능을 확인하는것은 올바르지 않다.

### **정밀도**

-   **정밀도(Precision)** : Positive로 예측한 경우 중 실제로 Positive인 비율이다
-    TP/FP+TP​

높을수록 좋은 모형이다. FDS의 경우, 사기 거래라고 판단한 거래 중 실제 사기 거래의 비율이 된다.

### **재현율**

-   **재현율(Recall)** : 실제 Positive인 것 중 올바르게 Positive를 맞춘 것의 비율 이다 
-   TP/FN+TP​, 민감도(Sensitivity) 혹은 TPR(True Positive Rate)이라고도 불린다.

높을수록 좋은 모형이다. FDS의 경우 실제 사기 거래 중에서 실제 사기 거래라고 예측한 거래의 비율이 된다. TPR(true positive rate) 또는 민감도(sensitivity)라고도 한다.

recall\=TPTP+FN

### **위양성율**

위양성율(fall-out)은 실제 양성 클래스에 속하지 않는 표본 중에 양성 클래스에 속한다고 출력한 표본의 비율을 말한다. 다른 평가점수와 달리 낮을수록 좋은 모형이다. FDS의 경우에는 실제로는 정상 거래인데 FDS가 사기 거래라고 예측한 거래의 비율이 된다. FPR(false positive rate)또는 1에서 위양성률의 값을 뺀 값을 특이도(specificity)라고도 한다.

fallout\=FPFP+TN

### **F1-Score**

-   F1 Score는 Precision과 Recall의 조화평균으로 주로 분류 클래스 간의 데이터가 불균형이 심각할때 사용한다.
-   앞에서 배운 정확도의 경우, 데이터 분류 클래스가 균일하지 못하면 머신러닝 성능을 제대로 나타낼 수 없기 때문에 F1 Score를 사용한다.
-   만약 정밀도와 재현율의 차이가 별로 없다면 F1 score는 그렇지 않은 모델보다 더 높은 값을 가지게 된다.​
-   높을수록 좋은 모델이다.  
    <img src="https://blog.kakaocdn.net/dn/bueeEi/btrjxb9H4eK/hrKi1Li8dzwGrwYX5PLai0/img.jpg">

### **ROC (Receiver Operation Characteristic Curve, 수신자 판단 곡선)**

-   위에서 설명한 각종 평가 점수 중 재현율(recall)과 위양성률(fall-out)은 일반적으로 양의 상관 관계가 있다.
-   ROC(Receiver Operator Characteristic) 커브는 클래스 판별 기준값의 변화에 따른 위양성률(fall-out)과 재현율(recall)의 변화를 시각화한 것이다.
-   재현율을 높이기 위해서는 양성으로 판단하는 기준(threshold)을 낮추어 약간의 증거만 있어도 양성으로 판단하도록 하면 된다. 그러나 이렇게 되면 음성임에도 양성으로 판단되는 표본 데이터가 같이 증가하게 되어 위양성율이 동시에 증가한다. 반대로 위양성율을 낮추기 위해 양성을 판단하는 기준을 엄격하게 두게 되면 증거 부족으로 음성 판단을 받는 표본 데이터의 수가 같이 증가하므로 재현율이 떨어진다.![](https://blog.kakaocdn.net/dn/cO4SkJ/btrjudUtJpH/BitFBL9IkhpnWYLYFKCweK/img.png)

<img src="https://blog.kakaocdn.net/dn/cO4SkJ/btrjudUtJpH/BitFBL9IkhpnWYLYFKCweK/img.png">

<img src="https://blog.kakaocdn.net/dn/lAUCk/btrjudfSXQa/LljXT1mJmI09FW3MOAo6Kk/img.png">
보통 위와 같은 그래프가 되고

그래프가 위로 갈 수록 좋은 모델이고, 적어도 Y=X 그래프보다 위에 있어야 어느정도 쓸모 있는 모델로 볼 수 있다.

## **AUC**

-   AUC값은 ROC곡선 밑의 면적을 구한 것으로 일반적으로 1에 가까울수록 좋은 수치이고,  
    0.5에 가까울수록 학습이 제대로 이루어지지 않은 모델이다.
-   AUC가 커지려면 FPR이 작은상태에서 얼마나 큰 TPR을 얻을수 있느냐가 관건이다.  
    즉 가운데 직선에서 멀어지고 왼쪽 상단 모서리쪽으로 가파르게 올라갈 수록 면적이 1에 가까워지는 좋은모델이 된다.
-   다중 클래스에 대해서는 정밀도, 재현율을 구하거나 ROC 커브를 그릴 수 없으므로 각각의 클래스에 대해 OvR 문제를 가정하고 각각의 OvR 문제에 대해 ROC 커브를 그린다.

  
  
출처:   
[https://bcho.tistory.com/1206](https://bcho.tistory.com/1206)

[https://velog.io/@ljs7463/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80%EC%A0%95%EB%B0%80%EB%8F%84%EC%9E%AC%ED%98%84%EC%9C%A8f1-score%EB%93%B1](https://velog.io/@ljs7463/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80%EC%A0%95%EB%B0%80%EB%8F%84%EC%9E%AC%ED%98%84%EC%9C%A8f1-score%EB%93%B1)  
[https://gggggeun.tistory.com/18](https://gggggeun.tistory.com/18) [https://datascienceschool.net/03%20machine%20learning/09.04%20%EB%B6%84%EB%A5%98%20%EC%84%B1%EB%8A%A5%ED%8F%89%EA%B0%80.html](https://datascienceschool.net/03%20machine%20learning/09.04%20%EB%B6%84%EB%A5%98%20%EC%84%B1%EB%8A%A5%ED%8F%89%EA%B0%80.html)  
[https://hleecaster.com/ml-accuracy-recall-precision-f1/](https://hleecaster.com/ml-accuracy-recall-precision-f1/)
