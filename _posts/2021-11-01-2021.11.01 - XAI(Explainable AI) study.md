학습목표 : XAI

학습정리기준:

1\. XAI가 뭘까 ?

2\. XAI종류 5가지 알아보기

3\. XAI의 필요성과 한계점

## **XAI 등장배경**

**XAI는 사람이 AI의 동작과 최종결과를 이해하고 올바르게 해석할 수 있고, **기존 인공지능 위에** 결과물이 생성되는 과정을 설명 가능하도록 해주는 기술을 의미한다.**

요즘 가장 각광받고 있는 AI(인공지능)은 단연 Neural Network(신경망)이다.

원래는 AI가 더 큰 의미를 지닌 단어이지만 근래에는 인기에 힘입어 AI가 Neural Network라는 뜻으로 통용되기도 한다. 뇌의 신경세포를 모방한 Neural Network는 서로 복잡하게 연결된 수백만개 이상의 parameter(매개변수)가 비선형으로 상호작용하는 구조로, 사람이 그 많은 parameter를 직접 계산하고 의미를 파악하기는 불가능하고

back propagation(오류역전파법) 덕에 간신히 parameter update만 가능하다.

복잡한 구조 덕에 성능은 기존 기계학습보다도 월등히 높아졌다. 어떤 분야에서는 사람보다도 정확하다.

그러나 사람의 인지 영역을 넘어선 내부 구조 탓에 AI가 왜 그런 결과를 도출했는지는 개발자도 알 수 없다.

그래서 AI를 Black Box라고 부르기도 한다.

---

## **XAI 의 필요성  
**

-   **기존 인공지능**  
    \- 주어진 데이터를 학습한 후  
    \- 새로운 데이터에 대하여 분류 및 예측  
      
    
-   **설명 가능한 인공지능**  
    \- 기존 인공지능 기능에 추가하여  
       - 결과에 대한 인과관계를 분석해서  
       - 적절한 근거 및 타당성을 찾아  
       - 인공지능 모델의 의사결정 결과를 사용자 레벨에서 설명하는 인공지능  
    \- 필요한 이유  
       - 인공지능 의사결정에 대하여 인간이 신뢰할 수 있음  
       - 특히 mission critical 한 응용분야에 필수  
       - ex) 의료, 국방, 법률, 금융 등  
    \- 법률적 제한  
       - 미국 평등신용기회법에서 신용결정 및 주택담보 대출 등 주요 금융 결정에 대해서 이유를  
         제시하도록 강제  
       - EU 2018년 5월 인공지능 알고리즘에 의해 자동으로 결정된 사안에 대해 회사에 설명을  
         강제하는 일반 정보 보호 규정 시행  
    

---

## **대표적인 XAI 종류**

| 관점 | 분류 |  |
| --- | --- | --- |
| Complexity | Intrinsic | Post-hoc |
| Scop | Global | Local |
| Dependency | Model-specific | Model-agnostic |

<img src="https://blog.kakaocdn.net/dn/bTbP9b/btrjnGX0KqZ/bwjYKNEWYgtOxaAK8fdczk/img.png">

### **Model-agnostic 설명법 ( 모델 귀납 )**

모델의 내부는 사람이 알 수 없으므로, 모델을 설명하기 위해서는 모델 밖에서 근거를 찾아야 한다는

이 이론은 모델의 종류에 관계없이 사용 가능한 방법

-   **Surrogate**  
    \- 설명 불가능한 모델 대신에 설명가능한 대리 모델을 따로 만들어서 설명하는 방법.  
    \- scope 관점에서 Global 기법에 속한다  
    \- 단점 : Original 모델을 완벽하게 설명할 수 없는 단점이 있다.  
    \- 장점 : Original 모델에 어떠한 변형도 가하지 않고 높은 정확도를 유지할 수 있다는 점과 간단하게 설명력을 얻을 수 있다.

-   **부분 의존 구성 (Partial Dependence Plots, PDP)  
    **\- 모델의 예측이 단일 입력에 어떻게 의존하는지를 보여주는 1-way 그래프이다.  
      관심변수를 제외한 관측치의 모든 변수의 값을 고정하고 특정 범위 내에서 관심변수를 변화시켜가며 예측값을 구    한다. 임의의 관심변수 값 1개에 대하여 관측치 개수만큼의 예측을 얻게 되는데, 이를 평균내어 출력한다.  
      계단 함수, 곡선, 선형 등과 같은 관계 유형을 보여준다.  
    \- 장점 : 모형의 평균적인 예측 경향성을 한눈에 알아볼 수 있다  
    \- 단점 : 변수 간 상호작용이 존재해도 이를 파악할 수 없다.  
               입력변수 사이의 상관관계가 강하게 존재하면 값을 변화시키는 그리드 내의 특정 데이터 포인트는  
               발생 가능성이 낮은 값이나 발생할 수 없는 값이 포함 될 수 있다는 것. -> CPG,ALE  
      
    
-   **개별 조건 예측 (Individual Conditional Expectations, ICE)  
    **\- PDP가 모델의 작동원리에 대한 대략적인 뷰를 제공하는 Global 기법인 반면   
      ICE는 개별 관측의 수준까지 상세하게 탐색할 수 있으므로 Local 기법의 특성도 갖는다. 평균값을 내는   
      PDP를 분리하므로 모델 변수들 간의 상호작용을 식별하는데도 도움이 된다.   
    \- ICE는 많은 입력 변수 사이에서 강한 관계가 있을 때 특히 유용하다.  
      
    
-   **일부 해석 모델 (Local Interpretable Model-agnostic Explantion, LIME)**  
    \- 입력값을 교란해 예측이 어떻게 바뀌는지를 확인함으로써 중요한 입력변수를 찾을 수 있다는 아이디어  
    \- 장점 : 모델에 대해 영향을 받지 않기 때문에 어떤 알고리즘에도 사용할 수 있다는 장점이 있다.  
               모델의 내부구조가 아무리 복잡하더라도 사람이 직관적으로 해석할 수 있다.  
      
    
-   **첨가 요인 민감도 (Sharply Additive Explanations, SHAP)  
      
      
    **
-   **계층별 관련도 전파법 (Layer-wise Relevance Propagation, LRP)**  
    \- 신경망 모델의 결과를 역추적해 각 입력에 대한 기여도를 계산하는 방법  
    \- LRP는 타당성 전파(Relevance Propagation)와 분해(Decomposition) 방법을 사용해 모델을 해부한다.  
      출력값에서부터 시작해 타당성 점수 또는 기여도라 불리는 relevance score를 입력단 방향으로 계산해 나가며 그    비중을 분배하는 방법이다.
      <img src="https://blog.kakaocdn.net/dn/cV8LWM/btrjAezck8c/KcKD1r188xiJ7Xd7fw86K1/img.png">
    \- 아래와 같이 어떠한 사진이 있고 학습된 신경망 모델이 이를 '수탉'이라고 분류했을때  
      LRP 알고리즘은 모델이 데이터의 어떤 부분을 보고 해당 결과를 도출해 내었는지 히트맵 형식으로 알려주는 방법  
    <img src="https://blog.kakaocdn.net/dn/D2V1G/btrjvRSiJ5v/KYSabGiIjozCYP3SD7K5UK/img.png">

### **Model-specific 설명법 ( 모델 특정적 )**

특정 모델만 적용할 수 있다는 점에서 모델을 고를때 선택권이 줄어드는 단점이 있다.

CNN게열에서만 쓸 수 있는 시각화 해석 기법은 모두 여기에 해당한다.

---

## **XAI의 설명력 테스트와 평가**

-   XAI가 갖춰야 할 설명요소

<img src="https://blog.kakaocdn.net/dn/cg5Dov/btrjAe0gErX/TOJcH39iXa3h2bCksn1HK0/img.png">

-   XAI의 설명역량 평가 요소  
      
    

<img src="https://blog.kakaocdn.net/dn/djwnlA/btrjueAfaf0/yDDAy2NCqSfpP13orUZXJ1/img.png">

---

## **XAI의 한계점**

-   XAI기법은 현상에 대한 모형의 예측을 설명하기 위한 것이지 현상 자체를 설명하기 위한 것이 아니며,  
    인과적 추론을 위해서는 도메인 지식을 기반으로 한 통제된 실험이 수반되어야 한다.  
      
    
-   전통적인 머신러닝 모델에 적용할 수 있는기법도 있다.  
    일반적으로 전통적인 모델에 적용하는XAI 기법은 딥러닝 기법에도 일부 적용이 가능하다.  
    그러나 딥러닝에 사용하는 XAI 기법들은 신경망을 이해하고 분해해야 하기 때문에 활용에 제약이 있다.  
    XAI 기법이 있는가 하면 딥러닝 모델에 적용할 수 있는 XAI 기법이 따로 있고, 모델의 제약 없이 적용할 수 있는

출처:   
책 < XAI 설명 가능한 인공지능, 인공지능을 해부하다 >  
[https://m.blog.naver.com/mayching1106/221249270216](https://m.blog.naver.com/mayching1106/221249270216)

[https://slidesplayer.org/slide/17749896/](https://slidesplayer.org/slide/17749896/)  
[https://realblack0.github.io/2020/04/27/explainable-ai.html](https://realblack0.github.io/2020/04/27/explainable-ai.html)
