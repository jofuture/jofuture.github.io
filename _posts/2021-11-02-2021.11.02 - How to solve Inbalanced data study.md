학습목표 : 불균형 데이터 해결방법

학습정리기준:

1\. 데이터불균형이 문제가 되는 이유와 그 방법

2\. 표준화, 로그변환, 이상치 제거 ,SMOTE

3\. 오버샘플링 해야할 때, 언더샘플링 해야할 때는 언제일까?

## **클래스 균형이 필요한 이유**  


왜 데이터가 클래스 균형을 이루어야할까? 그리고 언제 클래스 균형이 필요할까? 핵심은 다음과 같다. 

**클래스 균형 클래스 균형은 소수의 클래스에 특별히 더 큰 관심이 있는 경우에 필요하다.** 

머신러닝을 이용한 분류 모델 훈련에서 학습자료의 양과 질은 학습한 모델의 성능을 좌우하므로 학습자료 생성 이 매우 중요한 역할을 한다. 그러나 자료 생성에 높은 비용이 들어 이상적인 학습자료 생성이 어려울 때에는 클래스 간 자료 불균형 문제가 발생한다. 만약 학습자료로 사용될 탐사자료가 클래스 간 불균형하게 얻어지면, 클래스 별로 균형있 는 학습이 이루어지기 힘들다. 따라서 데이터가 상대적으로 적은 클래스는 재현율이 현저히 떨어지게 된다. 그 뿐만 아 니라 정확도와 정밀도 등의 평가지표들에 대한 신뢰도가 떨어지게 된다.

데이터 클래스 비율이 너무 차이가 나면(highly-imbalanced data) 단순히 우세한 클래스를 택하는 모형의 정확도가 높아지므로 모형의 성능판별이 어려워진다. 즉, 정확도(accuracy)가 높아도 데이터 갯수가 적은 클래스의 재현율(recall-rate)이 급격히 작아지는 현상이 발생할 수 있다.

비대칭 데이터는 다수 클래스 데이터에서 일부만 사용하는 **언더 샘플링**이나 소수 클래스 데이터를 증가시키는 **오버 샘플링**을 사용하여 데이터 비율을 맞추면 정밀도(precision)가 향상된다.

해결방법

-   Weight balancing
-   Over and under sampling  
    <img src="https://blog.kakaocdn.net/dn/QpExR/btrjsqUK16e/sUg0JlsxMqhlU0RJ2FThVK/img.png">

---

## **불균형 데이터 해결방법**

-   **표준화** 
      
-   **로그변환**
    \- 데이터의 분포가 심하게 왜곡되어 있을때 사용할 수 있는 기법  
    \- 원래 값을 log값으로 전환하여 값을 줄이게 되는데 이런 특징때문에 데이터 피쳐간의 단위가 크게   
      차이나는 경우에도 사용할 수 있다.  
      
    
-   **이상치 제거**  
      
-   **SMOTE**
    ADASYN 방법처럼 데이터를 생성하지만 생성된 데이터를 무조건 소수 클래스라고 하지 않고  
    분류 모형에 따라 분류한다.  
    SMOTE의 동작 방식은 데이터의 개수가 적은 클래스의 표본을 가져온 뒤 임의의 값을 추가하여  
    새로운 샘플을 만들어 데이터에 추가하는 오버샘플링 방식이다.  
    \- 먼저 소수 클래스에서 각각의 샘플들의 KNN(K-nearest neighbors)을 찾는다  
    \- 그리고 그 이웃들 사이에 선을 그어 무작위 점을 생성한다.  
    \- 이렇게 생성하면 완전히 동일하진 않지만 샘플들 사이의 특성들을 반영한 데이터가 생성되기 때문에  
      과적합에 나름대로 강한 데이터가 생성된다.  
    <img src="https://blog.kakaocdn.net/dn/bC0S4Z/btrjyIgjAqd/nBOhKVSQqtMYL3Q8JOVfoK/img.png">
    
    <img src="https://blog.kakaocdn.net/dn/V0rmD/btrjvTbzGIb/YfvCm5vwFKyXjxp3CVlfB1/img.png">
-   **ADASYN**  
    분포가 작은 클래스 데이터와 그 데이터와 가장 가까운 무작위의 K개의 데이터 사이에  
    가상의 직선을 그려서 직선상에 존재하는 가상의 분포가 작은 클래스 데이터를 생성하는 것  
    해당 방법론을 통해서 단순 무작위 오버샘플링으로 인해 발생하는 과적합 문제를 해결할 수 있다  
    단순 오버 샘플링은 데이터를 무작위로 가중치를 기반하여 복제하는 것이기 때문에 해당 방법론을 통한  
    오버샘플링이 좀 더 나은 방법론이라고 말 할 수 있을 것이다.  
    단점으로는 시간이 좀 걸리는 문제가 있다.  
      
    <img src="https://blog.kakaocdn.net/dn/Jei3N/btrjIzDiGyg/FQLkLJGZaFLTaoWkrDQFqK/img.png">
-   **MSMOTE**
-   **Cost-sensitive learning**

## **Over sampling VS Under sampling**

-   **Over sampling**  
    \- 데이터를 늘리기에 시간이 오래걸리고, 과하게 생성될 수 있으며 과적합 문제가 발생할 수 있음  
    \- 두 클래스를 구분짓는 의사결정경계가 과하게 커질 수 있고, 기존의 데이터 분포와는 달라질 수 있음  
    \=> 이런 문제 때문에 현재에는 Hybrid resampling 기법 (ex.DBSM)같은 것들이 개발  
      
    
-   **Under sampling**  
    장점 : Training set이 충분할 때 training set의 크기를 줄임으로써 실행 시간과 용량을 줄일 수 있다.  
    단점 : Classifier 를 만들 때 유용하게 사용될 수 있는 data가 유실될 수 있다  
            임의적으로 뽑은 sample이 편향(biasesd)됐을 수도 있고 모집단을 대표 하지 않을 수도 있다.  
            이로인해 Test set에서는 부정확한 결과가 초래할 수 있다.  
    \=> 학습속도향상의 이점보다 잃는 것이 많기 때문에 안하는게 좋아보인다.

출처:  
[https://datascienceschool.net/03%20machine%20learning/14.02%20%EB%B9%84%EB%8C%80%EC%B9%AD%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%AC%B8%EC%A0%9C.html](https://datascienceschool.net/03%20machine%20learning/14.02%20%EB%B9%84%EB%8C%80%EC%B9%AD%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%AC%B8%EC%A0%9C.html)  
[https://zzyunzz.tistory.com/21](https://zzyunzz.tistory.com/21)  
논문 <지도학습 기반 임상 분류 시 클래스 간 자료 불균형을 고려한 평가지표 개발>  
[https://www.koreascience.or.kr/article/JAKO202025863869781.pdf](https://www.koreascience.or.kr/article/JAKO202025863869781.pdf)  
[https://3months.tistory.com/414](https://3months.tistory.com/414)
