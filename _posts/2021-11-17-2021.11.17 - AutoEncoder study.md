## **오토인코더는 무엇인가?**

Autoencoder는 데이터를 효율적으로 coding하기위한 딥러닝 architecture중 한 가지이다.출력 데이터를 입력데이터와 비슷하게 만들어 (자기 자신을 재현할 수 있게) 학습하는 방법이다.결국 자기 자신이 정답 데이터가 되기 대문에 정답데이터를 따로 준비할 필요가 없다.따라서 비지도학습으로 분류된다.또한 어떤 데이터를 효율적으로 나타내기 위해서 고차원을 저차원으로 차원 축소하는 방법이다.Autoencoder의 신경망 구조는 input(입력)과 output(출력)이 동일하며 좌우를 대칭으로 구축된 구조이다.

\- 단순히 입력을 출력으로 복사하는 방법 학습

    - 다양한 방법으로 네트워크에 제약을 가해 작업을 어렵게 만듬 → 단순히 입력을 출력으로 바로 복사하지 못하도록 막고 data를 효율적으로 표현하는 방법을 배우게 만듬

    - 코딩은 일정 제약 조건하에서 Identity function을 학습하려는 autoencoder의 노력으로 생겨난 부산물

<img src="https://blog.kakaocdn.net/dn/edaJNZ/btrlgTahxo9/bC7ZvATkbVo4uLNGSMVMKK/img.png">

  
  

#### **구성요소**

-   Encoder : 인코딩을 위한 부분으로, 입력 데이터의 특징을 뽑아내는 것이라 할 수 있다.  
                 혹은 입력 데이터에 따른 고유한 패턴을 추출해낸다고도 생각해볼 수 있다.
-   Decoder : 내부 표현을 출력으로 바꾸는 부분 (생성 네트워크)

    - 출력층의 뉴런 수가 입력 개수와 동일하다는 것을 제외하면 대게 Autoencoder는 다층 퍼셉트론과 같은 구조

    - Autoencoder가 입력을 재구성하기 때문에 출력을 종종 Reconstruction(재구성)이라고 부름

    - 비용 함수는 Reconstruction과 입력이 다를 때 모델에 벌점을 부과하는 Reconstruction loss를 포함

  
  

#### **작동원리**

-   입력을 출력으로 복사하는 방법을 Train
-   다양한 방법 (잠재 표현 크기 제한, 잡음 추가 등)으로 네트워크에 제약을 가해 Train과정을 어렵게 만들 수 있음
-   재구성 (Reconstruction) : 오토인코더가 입력을 재구성한 Output
-   손실함수 : 재구성과 입력의 차이 ( = 재구성 손실 : reconstruction loss)

#### **학습과정**

1.  인풋과 히든 레이어의 가중치를 계산해 시그모이드 함수를 통과시킨다.
2.  1의 결과물과 출력 레이어의 가중치를 계산해 시그모이드 함수를 통과시킨다.
3.  2의 값을 이용해 MSE(Mean Squarded Error)를 계산한다.
4.  3의 결과로 나온 loss 값을 SGD로 최적화시키고

오류역전파를 사용하여 가중치를 갱신한다.

**AutoEncoder의 목적은 latent space( =manifold)를 학습하는데 있다.**

Latent Space란, 특정 차원에서 원하는 정보들이 모여있는 공간이다.

**Latent Space 혹은 Manifold란?**

\-> 높은 차원에서 특정 데이터들이 모여있는 공간

## **왜 오토인코더를 사용할까?**

오토인코더의 주요 응용 분야

-   이상 감지anomaly detection
-   이미지 노이즈 제거image denoising

오토인코더의 작업이 매니폴드 즉 주어진 데이터 매니폴드에 있는 데이터를 재건하는 것임을 알고 있고, 오토인코더가 해당 매니폴드 안에 존재하는 입력만 재건할 수 있기를 원한다.

따라서 우리는 모델이 훈련 중에 관찰한 것들만을 재건할 수 있도록 제한하고,

따라서 새로운 입력에 존재하는 어떠한 변화도 제거되는데,

왜냐하면 이 모델은 이러한 미세한 변화에 영향을 받지 않을것이기 때문이다.

오토인코더를 차원축소에 활용해야 하는 이유

PCA보다 sample 과 feature가 많은 대용량 데이터셋을 다루기 용이

## **오토인코더의 파생형**

오토인코더는 다음과 같은 여러개의 파생형을 가지고 있다.

-   Stacked Auto Encoder  
    오토인코더를 다층으로 만든 모델
-   Sparese Auto Encoder  
    히든 레이어 부분이 출력과 입력보다 큰 모델
-   Denoising Auto Encoder  
    노이즈가 있는 데이터가 주어졌을 때, 노이즈를 제거하여 원래의 데이터를 재현하는 모델.

출처:  
[https://ireland-ireland.tistory.com/entry/GAN-%EC%98%A4%ED%86%A0%EC%9D%B8%EC%BD%94%EB%8D%94%EC%99%80-GAN%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%9C-%ED%91%9C%ED%98%84-%ED%95%99%EC%8A%B5%EA%B3%BC-%EC%83%9D%EC%84%B1%EC%A0%81-%ED%95%99%EC%8A%B5](https://ireland-ireland.tistory.com/entry/GAN-%EC%98%A4%ED%86%A0%EC%9D%B8%EC%BD%94%EB%8D%94%EC%99%80-GAN%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%9C-%ED%91%9C%ED%98%84-%ED%95%99%EC%8A%B5%EA%B3%BC-%EC%83%9D%EC%84%B1%EC%A0%81-%ED%95%99%EC%8A%B5)

[https://lewisxyz000.tistory.com/22](https://lewisxyz000.tistory.com/22)

[https://yjjo.tistory.com/34](https://yjjo.tistory.com/34)

[https://atcold.github.io/pytorch-Deep-Learning/ko/week07/07-3/](https://atcold.github.io/pytorch-Deep-Learning/ko/week07/07-3/)
